## Synthesized Action Plan

### Immediate (before writing any code)
| # | Action | Recommended By | Why First | Effort |
|---|--------|---------------|-----------|--------|
| I1 | **Recalculate LLM budget with current Haiku pricing.** Spec uses Haiku 3 at $0.25/$1.25 per MTok. Current Haiku models are 3-5x more expensive. Validate whether $10/month is achievable with prompt caching, batch API, or pinned older model versions. This is a go/no-go for the entire project. | Researcher, Cloud, Commercial, Strategist | If the budget math does not work, the architecture must change before anything else happens. | 2-4 hours |
| I2 | **Define artefact JSON schemas for delivery state, RAID log, backlog, and decision log.** Include required fields, types, example values. These are the data contract the entire system builds on -- agent prompts, DB storage, frontend rendering all depend on them. | PM, Architect, Engineer, QA, DBA, Backend, AI/ML, Data, Writer, Content Strategist, Visionary | Every specialist identified this as the single biggest blocker. Nothing can be built without them. | 2-3 days |
| I3 | **Write a consolidated SPEC.md that replaces the three contradictory source documents.** Follow the 13-section structure from the consolidated plan. Include artefact schemas, DB schema, API routes, agent state machine, auth decision, and integration adapter contracts. | PM, Architect, Engineer, Writer, Copy Editor | Three contradictory documents guarantee implementation errors. One source of truth eliminates a class of problems. | 3-5 days |
| I4 | **Rename files and add deprecation banners.** Rename `# Fully Agentic PM Workbench - Complete .md` to `ARCHIVE-original-product-spec.md`. Rename `Orgiinal and Cloud Hosting Specif.ini` to `ARCHIVE-cloud-ui-spec.md`. Add "SUPERSEDED" banners. Update CLAUDE.md Key Files table. | Writer, Copy Editor | Current filenames break shell commands and the `.ini` extension is wrong. Takes 15 minutes. | 15 min |
| I5 | **Lock remaining open decisions:** Drizzle ORM (not Prisma), NextAuth.js with Credentials provider (env var password), custom agent loop (no LangGraph), polling first (no webhooks MVP), Jira Cloud only (not Server), Lucide icons with shadcn/ui, British English throughout. | Architect, DBA, Frontend, Designer, Copy Editor | Every open decision blocks downstream implementation. Lock them all now. | 1 hour |
| I6 | **Validate Azure AD app registration and Graph API permissions.** Register the app, request `ChannelMessage.Read.All` and `Mail.Read` permissions, test reading from a Teams channel and Outlook mailbox. If admin consent is unavailable, Teams and Outlook integrations are blocked. | Architect, Engineer, DevOps, Backend, Researcher, Journey Designer | This is an external dependency with organisational approval requirements. Start early even if integration code comes later. Finding out in week 8 that you cannot get admin consent wastes 8 weeks. | 1-2 days |
| I7 | **Verify Jira Cloud API access.** Generate a personal API token or register an OAuth 2.0 (3LO) app. Confirm you can read sprints, issues, changelogs, and comments for your target project. | Engineer, Backend | If your org restricts API tokens, Jira integration is blocked. | 2 hours |
| I8 | **Verify Neon free tier actual limits.** Confirm 0.5 GB storage (not 10 GB as the original spec claims), compute hours, connection limits, and cold start behaviour. Validate that the pooled connection endpoint works for serverless. | Cloud, DBA, Engineer, Data | The original spec's 10 GB claim is wrong. The entire storage strategy depends on knowing the real limit. | 1 hour |
| I9 | **Establish a personal PM activity baseline.** Track one week of actual PM time: status reports, RAID updates, Jira triage, email processing, stakeholder comms, meeting prep. This validates the time-savings claim and identifies the highest-ROI automation target. | Strategist, Researcher, Commercial | If actual PM overhead is 8 hours/week, not 20, the ROI arithmetic changes. Build the highest-value feature first. | 1 week (passive) |

### Phase 0: Spikes & Validation
| # | Spike | Recommended By | Question to Answer | Effort |
|---|-------|---------------|-------------------|--------|
| S1 | **Artefact generation quality.** Feed real Jira project data (sprint board, backlog, recent changes) to Claude with tool-use schemas. Ask it to generate a delivery state and RAID log. Run 10+ iterations. Evaluate: Is output useful? Is structure consistent? Does it match the defined JSON schemas? | AI/ML, QA, Engineer, Strategist | If Claude cannot reliably generate structured artefacts with tool-use, the core product does not work. This is the existential risk. | 1-2 days |
| S2 | **Token usage measurement.** Build a minimal polling loop that reads from a test Jira project and calls Haiku for signal detection using the actual prompt templates. Measure tokens per cycle. Extrapolate monthly cost at current Haiku pricing. Test with prompt caching enabled. | AI/ML, Cloud, Data, Commercial | The $10/month ceiling is the hardest constraint. If token costs blow past it, you need to adjust polling frequency, prompt size, or model choice before committing to the architecture. | 1 day |
| S3 | **Microsoft Graph API access.** Register an Azure AD app, grant application permissions, test reading Teams channel messages and Outlook emails. Document the exact setup steps, required permissions, and any admin consent blockers. | Engineer, Backend, Journey Designer | If you cannot get application permissions, half the integration surface disappears. Learn this now, not in week 6. | 1-2 days |
| S4 | **Neon free tier performance.** Simulate the agent's access pattern: connect, run 5-10 queries, disconnect, wait 15 minutes, repeat for 24 hours. Measure cold start latency. Test the pooled connection endpoint from a serverless function. | Cloud, Perf, Engineer | Every agent cycle will hit a cold start. If latency is 5+ seconds consistently, a keepalive strategy is mandatory. | 1 day |
| S5 | **Evaluate n8n as integration/polling layer.** Spend half a day testing whether n8n self-hosted on the VPS can handle Jira polling and signal forwarding to a custom processing pipeline. Determine if it cuts integration development time meaningfully. | Researcher, Strategist | If n8n saves 3-4 weeks of integration code, the build timeline compresses dramatically. Worth a quick look before committing to custom adapters. | 4 hours |

### Phase 1: Foundation
| # | Action | Recommended By | Dependencies | Effort |
|---|--------|---------------|-------------|--------|
| F1 | **Provision Hetzner VPS with a reproducible setup script (`infra/provision.sh`).** Install Node.js, pm2, configure UFW (SSH + HTTPS only), disable password SSH, create non-root app user, install `unattended-upgrades`, set up pm2-logrotate. Check the script into the repo. | DevOps, Security, SRE | Hetzner account | 3-4 hours |
| F2 | **Set up Caddy as reverse proxy on VPS from day one.** Point a subdomain at the VPS IP. Even if you start polling-only, the infrastructure for webhooks and a `/health` endpoint is ready. | Architect, Cloud | DNS, VPS provisioned (F1) | 1-2 hours |
| F3 | **Create Neon database with complete schema.** Use Drizzle ORM. Design tables: `projects`, `artefacts`, `escalations`, `agent_actions`, `agent_checkpoints`, `integration_configs`, `agent_config`, `events`. Use `TIMESTAMPTZ` everywhere. Use `JSONB` for artefact content. Add `version INT` for optimistic concurrency on mutable tables. | Architect, DBA, Engineer, i18n | Artefact schemas (I2), ORM decision locked (I5), Neon verified (I8) | 2-3 days |
| F4 | **Create shared `packages/db` with Drizzle schema definitions.** Both the VPS agent and Vercel frontend import from this package. VPS uses `pg` driver; Vercel uses `@neondatabase/serverless`. | Architect | Schema defined (F3) | 4-6 hours |
| F5 | **Deploy empty Next.js app to Vercel with auth.** Use NextAuth.js with Credentials provider (env var password). Set up middleware-based route protection. Single hardcoded user. HTTP-only secure cookies. | Frontend, Security | Vercel account, auth decision locked (I5) | 4-6 hours |
| F6 | **Build basic dashboard with empty states.** Mission Control route, Activity Feed route, Settings route. Use shadcn/ui + Lucide icons. Design the empty state for each view ("No projects yet -- create your first project"). Static shell + client-side data fetch pattern. | Frontend, Designer, Journey Designer | Next.js deployed (F5), shadcn/ui initialized | 2-3 days |
| F7 | **Deploy basic agent process to VPS under pm2.** The agent writes a heartbeat to the `events` table every cycle. Use structured JSON logging via pino. Handle SIGINT/SIGTERM for graceful shutdown. Configure pm2 ecosystem file with `max_memory_restart` and log rotation. | Engineer, SRE, DevOps | VPS provisioned (F1), DB schema (F3) | 1-2 days |
| F8 | **Implement agent heartbeat and display in frontend.** Agent writes `last_heartbeat` to DB every cycle. Frontend shows "Agent last active: X minutes ago." Red warning if stale >20 minutes. | SRE, Frontend, Journey Designer | Agent running (F7), Dashboard exists (F6) | 3-4 hours |
| F9 | **Set up external health check.** Use Healthchecks.io (free): agent pings a URL at end of each cycle. If ping stops, email alert. | SRE, Cloud, DevOps | Agent running (F7) | 1 hour |
| F10 | **Implement LLM call abstraction with cost tracking.** Wrap all Claude API calls in a single function that: selects model based on task type, uses tool-use for structured output, logs input/output token counts to `agent_actions`, enforces daily/monthly budget with circuit breaker, validates output with Zod. | Architect, AI/ML, Data, Cloud, Commercial | Claude API key, Zod schemas from artefact definitions (I2) | 1-2 days |
| F11 | **Implement budget controls from day one.** Track cumulative spend in DB. Degradation ladder: >$0.20/day = Haiku-only; >$0.30/day = reduce polling to 30 min; >$0.40/day = monitoring-only (no LLM calls). Surface current spend in the Settings page. | Cloud, Commercial, Data, PM | LLM abstraction (F10), DB schema (F3) | 4-6 hours |
| F12 | **Set up GitHub Actions for VPS deployment.** On push to `main`: SSH to VPS, git pull, npm install, pm2 reload. Post-deploy health check. | DevOps | Repo on GitHub, VPS provisioned (F1) | 2-3 hours |
| F13 | **Implement Neon keepalive from the VPS agent.** Send a `SELECT 1` every 4 minutes to prevent cold starts during working hours. Configurable schedule. | Cloud, Perf | Agent running (F7), Neon configured (F3) | 30 min |

### Phase 2: Core Product
| # | Action | Recommended By | Dependencies | Effort |
|---|--------|---------------|-------------|--------|
| C1 | **Build Jira Cloud integration adapter.** Implement `SignalSource` interface: `authenticate()`, `fetchDelta(since)`, `normalizeSignals()`, `healthCheck()`. Use Jira REST API v3 with OAuth 2.0 (3LO). Store refresh tokens encrypted in `integration_configs`. Handle pagination, rate limits (100 req/min), and 429 backoff. | Backend, Engineer, Architect | Jira API access verified (I7), adapter interface defined in SPEC.md (I3) | 3-5 days |
| C2 | **Build signal normalization pipeline.** Transform raw Jira changelogs into a common `Signal` shape: `id`, `sourceIntegration`, `signalType`, `timestamp`, `summary`, `deduplicationKey`. Deduplication by key prevents re-processing after agent restart. | Backend | Jira adapter (C1) | 1-2 days |
| C3 | **Implement two-pass triage architecture.** Pass 1: Haiku classifies each signal as routine/complex/uncertain using tool-use. Pass 2: Routine signals handled by Haiku; complex/uncertain routed to Sonnet with full project context. This replaces the static 85/15 split with adaptive routing. | AI/ML | LLM abstraction (F10), signal normalization (C2) | 2-3 days |
| C4 | **Implement context assembly layer.** `ContextAssembler` takes (project_id, signal_batch, call_type) and returns a token-budgeted payload. Always includes artefact summaries; full detail only for current signals; injects relevant few-shot examples from override history. Testable independently of Claude. | AI/ML | Artefact schemas (I2), LLM abstraction (F10) | 2-3 days |
| C5 | **Agent generates delivery state artefact from Jira data (bootstrap).** On first connection, Claude synthesizes a "Project Intelligence Brief" from Jira sprint/backlog data. Present to user as a reviewable document, not silently committed. User reviews, corrects, approves. | Visionary, PM, Journey Designer | Jira adapter (C1), context assembly (C4), artefact schemas (I2) | 3-5 days |
| C6 | **Agent detects changes and updates artefacts on each cycle.** Change-detection gate: compare timestamps/ETags before calling Claude. If nothing changed, skip LLM calls (zero cost). When changes detected, agent updates delivery state and RAID log via tool-use. Store previous version in `previous_version JSONB` column (one-deep undo). | Cloud, Backend, Architect | Bootstrap working (C5) | 3-5 days |
| C7 | **Implement dry-run/sandbox mode as a first-class feature.** Every action has a `dryRun` flag. When enabled, agent logs what it would do with full details but skips execution. Actions stored with `status = 'simulated'`. This IS Level 1 (Monitoring) autonomy. Toggleable in Settings page. | QA, Architect, Engineer, PM | Agent loop with actions (C6) | 1-2 days |
| C8 | **Build Activity Feed with cursor-based pagination.** Use the `events` table as the backbone. Frontend polls with `WHERE id > :last_seen_id`. Use TanStack Query with 30-second refetch interval. Virtual scrolling with `@tanstack/react-virtual` for performance. Heartbeat entries ("Checked Jira: 0 changes") visually de-emphasised. | Architect, Frontend, Journey Designer | Events table populated by agent (C6), Dashboard (F6) | 2-3 days |
| C9 | **Build Escalation workflow.** Agent creates escalations for significant changes (new risks, blockers, milestone impacts). Decision Interface as a dedicated page (`/decisions/[id]`). Options: Approve, Reject, Snooze (resurface later), Need More Info. Store user decision with timestamp. Log confidence score and outcome for calibration tracking. | PM, QA, DBA, Journey Designer | Agent detecting changes (C6), DB schema (F3) | 3-5 days |
| C10 | **Implement integration health tracking.** Each adapter implements `healthCheck()`: verify token validity, API reachability, expected resources exist. Display per-integration status in sidebar: "Jira: connected, last synced 12m ago | Outlook: token expired, action required." | SRE, Journey Designer, Backend | Jira adapter (C1) | 1-2 days |
| C11 | **Build agent cycle telemetry.** One row per cycle in `agent_cycles`: started_at, completed_at, integrations_polled, signals_detected, actions_taken, llm_calls (model, tokens, cost), errors. This replaces vague monitoring with queryable data. | Data, Perf | Agent loop running (C6) | 4-6 hours |
| C12 | **Implement circuit breakers per integration.** 3 consecutive failures = stop calling that integration for 30 minutes. Agent logs "Integration X offline, skipping" and continues with others. Prevents cascading failures. | QA, Backend | Integration adapters (C1) | 3-4 hours |
| C13 | **Poll integrations in parallel.** Use `Promise.allSettled()` for all integration API calls. One failing integration does not block others. Cuts worst-case cycle time from 40+ seconds to the slowest single call. | Perf, Backend | Multiple integrations working | 1-2 hours |

### Phase 3: Enhancement
| # | Action | Recommended By | Dependencies | Effort |
|---|--------|---------------|-------------|--------|
| E1 | **Build Outlook integration via Microsoft Graph API.** Use MSAL for token acquisition/caching/refresh. Use delta queries (`/messages/delta`) for efficient polling. Store `deltaLink` token in `agent_checkpoints`. Email signals feed into artefact updates and cross-source correlation. | Backend, Engineer | Azure AD app registered (I6/S3), adapter interface (C1 pattern) | 3-5 days |
| E2 | **Implement draft-then-send for outbound communications.** Even at Level 3, agent saves drafted emails as pending actions with a configurable delay (default: 30 min). User can intercept, edit, or let timer auto-send. This is the minimum viable safety net for autonomous email. | AI/ML, Visionary, Strategist, Content Strategist | Outlook integration (E1) | 2-3 days |
| E3 | **Build Level 2 autonomous artefact maintenance.** Agent updates artefacts without approval. Confidence-based guardrails: replace self-reported LLM confidence with structured signals (action type in `canAutoExecute`, signal from trusted source, action reversible, response schema-valid). | AI/ML, QA, PM | Sandbox mode proven stable (C7), escalation workflow working (C9), sufficient Level 1 runtime data | 2-3 days |
| E4 | **Implement autonomy graduation ceremony.** Before Level 1 to 2 transition, show summary: "Over 14 days: 892 signals monitored, 23 actionable items identified, 0 false positives at P0 severity." Explicit user confirmation. Minimum thresholds configurable. | PM, UX Psychologist, Journey Designer | Level 2 implemented (E3), cycle telemetry (C11) | 1-2 days |
| E5 | **Build MS Teams read-only integration.** Use Microsoft Graph API (same Azure AD app as Outlook). Monitor configured channels for project-related signals. Polling (not webhooks) -- Teams webhook subscriptions expire after 60 minutes. | Backend | Azure AD app with Teams permissions (S3) | 2-3 days |
| E6 | **Implement data retention policy.** Weekly maintenance task on VPS: delete `agent_actions` older than 90 days, collapse artefact `previous_version` older than 30 days, aggregate old `agent_cycles` into `daily_stats`. Monitor `pg_database_size()` and alert at 350 MB. | DBA, Cloud, Data | DB schema (F3), agent running | 4-6 hours |
| E7 | **Build reasoning transparency in UI.** Every agent action in the activity feed has an expandable "Why I did this" section: signal detected, interpretation applied, confidence breakdown, alternatives considered. | UX Psychologist, QA | Agent logging full reasoning (C11, F10) | 2-3 days |
| E8 | **Implement decision memory (structured override log).** When user overrides agent decision, store: original signal, proposed action, chosen action, user's reason. Inject last N relevant overrides as few-shot examples in future prompts for similar scenarios. Simple SQL query on action type -- no vector DB needed. | AI/ML, Visionary, UX Psychologist | Escalation workflow (C9) | 1-2 days |
| E9 | **Build daily digest as email.** Each morning at configurable time, agent sends concise email via Outlook: decisions waiting, notable events (3-5 items), routine activity summary ("47 routine actions, no issues"). Link to dashboard. | Content Strategist, Journey Designer, PM | Outlook send capability (E1) | 1-2 days |
| E10 | **Implement prompt injection defence layer.** Never pass raw external content directly to reasoning prompts. Use a separate, tool-less Haiku call to extract structured data from external content. Pass only structured extraction to decision prompts. Validate all agent output actions against an outbound action allowlist (only configured email addresses, only configured Jira projects). | Security | Two-pass triage (C3) already provides the architecture | 1-2 days |
| E11 | **Frontend polish: loading states, error states, skeleton screens.** Skeleton placeholders during Neon cold starts. "Last refreshed X seconds ago" timestamps. Error banners for agent offline, integration failures, DB unreachable. "No escalations pending" content instead of blank panels. | Designer, Frontend, Journey Designer, A11y | Dashboard built (F6, C8) | 2-3 days |
| E12 | **Add `prefers-reduced-motion` support and basic accessibility.** Colour + icon + text for all status indicators (not colour-only). Sufficient contrast ratios. Keyboard navigation for decision interface. `role="log"` with `aria-live="polite"` on activity feed. | A11y, Designer | Frontend built | 1-2 days |

### Deferred (post-MVP, explicitly)
| # | Action | Why Defer | Revisit When |
|---|--------|----------|-------------|
| D1 | Asana integration | MVP validates with Jira first. Asana is a separate 2-3 week effort with different API, auth, and data model. | After Jira integration is stable for 4+ weeks |
| D2 | Level 3 autonomy (sending emails, updating Jira tickets) | Highest-risk autonomous actions. Requires months of trust-building data at Level 2. | After 30+ days at Level 2 with 95%+ approval rate |
| D3 | Analytics/performance dashboard ("Time Saved", decision accuracy metrics) | Nice to have but not core value. Define "Time Saved" as a configurable lookup table, not a measured value. | After core artefact maintenance is proven valuable |
| D4 | Automated learning loop | Statistically meaningless with 20-50 feedback signals per month. Manual prompt tuning informed by override data (E8) is more effective. | Possibly never. Manual tuning is the right approach at this scale. |
| D5 | Webhook-first architecture (Jira, Outlook) | Polling works and is simpler. Webhooks improve responsiveness but add public endpoint complexity, subscription management, and webhook secret rotation. VPS is already behind Caddy (F2) so infrastructure is ready when you want it. | When polling latency becomes a user-visible problem |
| D6 | Mobile-responsive design | Personal work tool. User will use desktop 99% of the time. shadcn/ui provides basic mobile usability for free. Outlook email notifications serve as mobile alerting. | Only if "meeting glance" use case proves real |
| D7 | Dark mode | Low value relative to effort. shadcn/ui supports it via CSS variables, so retrofitting is cheap later. | When the user wants it |
| D8 | Status report auto-generation and auto-sending | Requires proven Outlook integration, proven artefact quality, and Level 3 autonomy. Draft-then-send mode (E2) is the safe intermediate step. | After draft quality is validated over 10+ manual sends |
| D9 | Backlog artefact | Delivery state and RAID log cover the highest-value PM artefacts. Backlog is largely redundant with Jira's own backlog view. | When the user identifies a concrete unmet need |
| D10 | Project archival and lifecycle management | With 1-2 projects, manual DB cleanup is fine. Formalise when project count grows. | When running 3+ projects or after 6 months of operation |
| D11 | Communication preview / auto-send graduation system | Content Strategist's recommendation that first N emails of each type go through preview queue, then auto-send after 10 consecutive approvals with no edits. Solid idea but requires stable Outlook integration first. | When implementing Level 3 outbound communications |

### Recommendations Rejected or Deprioritised
| # | Recommendation | From | Why Deprioritised |
|---|---------------|------|------------------|
| R1 | Passkey (WebAuthn) authentication for frontend | Security | Overkill for a single-user personal tool. NextAuth.js with Credentials provider and an env var password gives session management, CSRF protection, and secure cookies with a fraction of the effort. Passkey adds library dependencies and a challenge/response flow for one user. |
| R2 | Encrypt OAuth tokens with a key stored on Vercel (not VPS) | Security | For a personal tool, this adds latency and a circular dependency (agent needs Vercel to get tokens). Storing the encryption key as an env var on the VPS with proper file permissions (chmod 600 on `.env`) is sufficient. The VPS is already behind a firewall with SSH-key-only access. |
| R3 | Preserve SaaS optionality with `user_id` columns | Commercial | The consolidated plan explicitly strips multi-user patterns. Adding `user_id` to every table creates conceptual confusion ("is this multi-tenant?") and clutters every query. If SaaS is ever pursued, it is a different product requiring a different architecture. The migration cost is the same either way. |
| R4 | Evaluate n8n as the full agent orchestration layer (replace custom code) | Researcher | n8n is worth spiking (S5) for the integration/polling layer, but replacing the entire custom agent with n8n workflows sacrifices control over the reasoning pipeline, prompt engineering, and structured output handling -- which is where the core value lives. Use n8n as a utility if the spike proves useful, not as the architecture. |
| R5 | Full three-tier animation system with motion tokens | Motion | A personal productivity tool does not need a formally specified animation system. CSS transitions with `prefers-reduced-motion` support cover 100% of MVP needs. The "calm technology" principle is correct; the formal specification of it is unnecessary. |
| R6 | Detailed motion inventory per view | Motion | Same reasoning as R5. Use CSS transitions, keep animations under 250ms, and move on. |
| R7 | WCAG 2.1 AA compliance target with full audit | A11y | For a single-user personal tool, formal compliance is not needed. However, the practical recommendations (colour + icon + text, sufficient contrast, keyboard-navigable decision interface, `prefers-reduced-motion`) are good engineering and should be followed. Adopted the practical items (E12), rejected the formal compliance target. |
| R8 | Kanban drag-and-drop with keyboard alternative | A11y | Kanban task queue is not in MVP scope. When/if it is added, a simple priority dropdown is better than drag-and-drop for a single-user tool. |
| R9 | Golden scenario test suite of 20-30 scenarios before writing agent code | QA | The principle is sound but 20-30 scenarios before any code is excessive for a personal tool. The artefact generation spike (S1) validates the core capability. Build 5-10 golden scenarios incrementally as the agent matures, not all upfront. |
| R10 | Formal false positive/false negative budgets per action type | QA | Statistical quality targets are meaningless at the data volumes this tool will produce (20-50 escalations/month). Use manual review of override data (E8) to tune prompts. The structured override log IS the quality feedback mechanism. |
| R11 | Full incident response plan with break-glass procedure | Security | A single-user tool needs a simple runbook, not a formal incident response plan. Document how to: revoke OAuth tokens, rotate API keys, restart the agent. That is the "plan." |
| R12 | Systemd over pm2 for process management | SRE | pm2 is simpler to configure, provides log management, monitoring, and ecosystem files out of the box. Systemd is "more correct" but pm2 is more productive for a solo developer. DevOps and Engineer also recommend pm2. |
| R13 | Formal agent voice/personality naming exercise ("Sentinel", "Vigil") | Storyteller | Naming the agent is a branding exercise, not a technical one. It has zero impact on whether the product works. Call it "the agent" and move on. |
| R14 | "Origin story" narrative as the spec's opening section | Storyteller | The user IS the origin story. They know their own pain. Spec documents need schemas and contracts, not prose narratives. |
| R15 | Anti-complacency spot check every 2 weeks | UX Psychologist | Good idea in theory. In practice, with 1-2 projects and manual prompt tuning from override logs (E8), the user is already reviewing agent decisions regularly. Adding a formal "spot check" mechanism is premature. If automation complacency becomes a real problem, revisit. |
| R16 | "Trust dial" continuous slider replacing discrete autonomy levels | UX Psychologist | Discrete levels (1-4) are clearer, easier to implement, and easier to reason about. A continuous slider sounds elegant but creates ambiguity about what the agent can and cannot do at any given position. Keep it discrete. |
| R17 | Build-vs-buy analysis document comparing Zapier/Make/VA alternatives | Commercial, Strategist | The user has already committed to building. A formal analysis at this point is procrastination. The spike phase (S1-S5) validates whether the custom build delivers value that off-the-shelf tools cannot. |
| R18 | Full disaster recovery runbook with RTO/RPO targets | DevOps | For a $4/month VPS running a personal tool, the recovery plan is: spin up a new VPS, run `provision.sh`, deploy from git, reconnect to Neon. Formalising RTO/RPO targets is enterprise thinking applied to a personal project. |
| R19 | SQLite for local development instead of Neon | Engineer | Adds a second database driver path and risks subtle behaviour differences between SQLite and PostgreSQL (especially for JSONB). Use Neon branching (free tier supports it) for dev/test instead. |
| R20 | Content Type Registry as a formal document | Content Strategist | The artefact schemas (I2) and prompt templates already define output structure. A separate Content Type Registry is a documentation overhead that duplicates information in the schemas. |
| R21 | GPT-4o Mini as fallback LLM if Claude pricing changes | Researcher | Worth noting as a contingency, but not worth building dual-LLM support into MVP. If Claude pricing becomes untenable, switch entirely rather than maintaining two LLM integrations. |
| R22 | Docker as optional convenience | DevOps | Agreed with the "optional convenience" framing but do not invest time writing a Dockerfile for MVP. pm2 on bare metal is simpler. Add Docker if/when deployment complexity justifies it. |
